name: VIDEO ENHANCER (QUALITY)

on:
  workflow_dispatch:
  # schedule:
  #   - cron: '30 3 * * *'   # 9:00 AM IST
  #   - cron: '30 6 * * *'   # 12:00 PM IST
  #   - cron: '30 9 * * *'   # 3:00 PM IST
  #   - cron: '30 12 * * *'  # 6:00 PM IST
  #   - cron: '30 15 * * *'  # 9:00 PM IST

jobs:
  run-on-kaggle:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      # =======================
      # 1. Checkout Repo
      # =======================
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          sparse-checkout: |
            ipnby/quality.ipynb
            video_enhancer_quality/
            counter.txt
            requirements.txt
          fetch-depth: 1

      # Read the counter value and set sparse-checkout for the specific video
      - name: Configure Sparse Checkout for Specific Video
        run: |
          VIDEO_NUMBER=$(cat counter.txt)
          echo "Setting sparse-checkout for Video_${VIDEO_NUMBER}.mp4"
          echo "private/videos/Video_${VIDEO_NUMBER}.mp4" >> .git/info/sparse-checkout
          echo "public/videos/test.mp4" >> .git/info/sparse-checkout
          git sparse-checkout reapply

      # =======================
      # 2. Install Kaggle API
      # =======================
      - name: Install Kaggle API
        run: pip install kaggle

      # =======================
      # 3. Configure Kaggle API
      # =======================
      - name: Configure Kaggle
        run: |
          mkdir -p ~/.kaggle
          echo "{\"username\":\"${{ secrets.KAGGLE_USERNAME }}\",\"key\":\"${{ secrets.KAGGLE_KEY }}\"}" > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json

      # =======================
      # 4. Package Repo Files as Kaggle Dataset
      # =======================
      - name: Prepare Dataset Folder
        run: |
          mkdir -p kaggle-dataset
          cp -r video_enhancer_quality kaggle-dataset/ || true
          cp counter.txt kaggle-dataset/ || true
          cp requirements.txt kaggle-dataset/ || true
          cp ipnby/quality.ipynb kaggle-dataset/ || true
          
          mkdir -p kaggle-dataset/public/videos
          cp "public/videos/test.mp4" kaggle-dataset/public/videos/ || echo "‚ö†Ô∏è test.mp4 not found"
          
          VIDEO_NUMBER=$(cat counter.txt)
          mkdir -p kaggle-dataset/private/videos
          cp "private/videos/Video_${VIDEO_NUMBER}.mp4" kaggle-dataset/private/videos/ || echo "‚ö†Ô∏è Video file not found: private/videos/Video_${VIDEO_NUMBER}.mp4"

          # Kaggle dataset metadata
          cat > kaggle-dataset/dataset-metadata.json <<EOF
          {
            "id": "${{ secrets.KAGGLE_USERNAME }}/video-enhancing-data",
            "title": "Video Enhancing Data",
            "licenses": [
              { "name": "CC0-1.0" }
            ],
            "isPrivate": true
          }
          EOF

      - name: Create or Update Kaggle Dataset
        run: |
          for i in $(seq 1 5); do
            if kaggle datasets status ${{ secrets.KAGGLE_USERNAME }}/video-editing-data >/dev/null 2>&1; then
              echo "‚úÖ Dataset exists, versioning... (Attempt $i)"
              if kaggle datasets version -p kaggle-dataset -m "Update dataset for run" --dir-mode zip; then
                echo "‚úÖ Versioning successful"
                break
              fi
            else
              echo "‚ö° Dataset not found, creating... (Attempt $i)"
              if kaggle datasets create -p kaggle-dataset --dir-mode zip; then
                echo "‚úÖ Creation successful"
                break
              fi
            fi
            
            if [ $i -lt 5 ]; then
              echo "‚ö†Ô∏è Command failed. Retrying in 30 seconds..."
              sleep 30
            else
              echo "‚ùå Command failed after 5 attempts."
              exit 1
            fi
          done

      - name: List datasets for ${{ secrets.KAGGLE_USERNAME }}
        run: |
          echo "üì¶ Listing datasets for user: ${{ secrets.KAGGLE_USERNAME }}"
          sleep 60  # Wait a bit to ensure Kaggle has updated
          kaggle datasets list --user ${{ secrets.KAGGLE_USERNAME }}

      # =======================
      # 5. Prepare Kernel Metadata
      # =======================
      - name: Prepare Kernel Metadata
        run: |
          cat > kernel-metadata.json <<EOF
          {
            "id": "${{ secrets.KAGGLE_USERNAME }}/video-enhancing-notebook",
            "title": "Video Enhancing Notebook",
            "code_file": "ipnby/quality.ipynb",
            "language": "python",
            "kernel_type": "notebook",
            "is_private": true,
            "enable_gpu": true,
            "enable_internet": true,
            "dataset_sources": [
              "${{ secrets.KAGGLE_USERNAME }}/video-enhancing-data"
            ],
            "competition_sources": [],
            "kernel_sources": [],
            "model_sources": []
          }
          EOF

      # =======================
      # 6. Push Notebook Kernel (auto-runs)
      # =======================
      - name: Push notebook to Kaggle
        run: kaggle kernels push -p .

      # =======================
      # 7. Wait for Kaggle Notebook to finish
      # =======================
      - name: Wait for Kaggle notebook to finish
        run: |
          KERNEL_ID="${{ secrets.KAGGLE_USERNAME }}/video-enhancing-notebook"
          for i in $(seq 1 60); do
            STATUS=$(kaggle kernels status $KERNEL_ID)
            echo "[$i] Status: $STATUS"
            if [[ "$STATUS" == *"KernelWorkerStatus.COMPLETE"* ]]; then
              echo "‚úÖ Kernel Complete"
              exit 0
            elif [[ "$STATUS" == *"KernelWorkerStatus.ERROR"* ]]; then
              echo "‚ùå Kernel Error"
              exit 1
            elif [[ "$STATUS" == *"KernelWorkerStatus.RUNNING"* || "$STATUS" == *"KernelWorkerStatus.QUEUED"* ]]; then
              echo "‚úÖ Kernel running"
            fi
            sleep 60
          done

      # =======================
      # 8. Download Notebook Outputs
      # =======================
      - name: Download notebook outputs
        run: kaggle kernels output ${{ secrets.KAGGLE_USERNAME }}/video-enhancing-notebook -p ./outputs

      # Copy processed videos from download to local folders
      - name: Copy processed videos to local folders
        run: |
          echo "üìÅ Copying processed videos from Kaggle outputs..."
          cp -r ./outputs/repo/public/videos/* public/videos/ 2>/dev/null || echo "No public/videos files to copy"
          echo "‚úÖ Copy completed. Current contents:"
          ls -la public/videos/ 2>/dev/null || echo "public/videos folder empty"

      # =======================
      # 9. Commit results back to GitHub
      # =======================
      - name: Commit and Push Changes
        run: |
          git config --local user.name "github-actions"
          git config --local user.email "github-actions@github.com"
          git add --sparse public/videos/ || echo "Nothing to add"
          git commit -m "Update reels after Kaggle GPU notebook run" || echo "No changes"
          git pull --rebase origin main || echo "No changes"
          git push || echo "No changes"

      # =======================
      # 10. Delete Kaggle Dataset
      # =======================
      - name: Delete Kaggle Dataset
        run: |
          echo "üóëÔ∏è Deleting dataset ${{ secrets.KAGGLE_USERNAME }}/video-enhancing-data..."
          kaggle datasets delete ${{ secrets.KAGGLE_USERNAME }}/video-enhancing-data --yes || echo "‚ö†Ô∏è Dataset delete command may have failed"